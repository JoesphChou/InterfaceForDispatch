import pandas as pd
import urllib3
import re
from bs4 import BeautifulSoup

def scrapy_schedule():
    """
    è§£æ 2138 å’Œ 2137 é é¢ï¼Œç²å–ä¸åŒè£½ç¨‹ (EAF, LF1-1) çš„æ’ç¨‹
    - **ç¢ºä¿ EAF & LF1-1 å„è‡ªç¨ç«‹å»é‡è¤‡ï¼Œä¸å½±éŸ¿å½¼æ­¤**
    - **ç¢ºä¿ LF1-1, LF1-2 past & future ä¸æœƒæ¶ˆå¤±**
    - **ç¢ºä¿ 2137 é è¨ˆå®Œæˆæ™‚é–“è§£ææ­£å¸¸**
    è§£æ 2138 å’Œ 2137 é é¢ï¼Œç²å–ä¸åŒè£½ç¨‹ (EAF, LF1-1, LF1-2) çš„æ’ç¨‹ï¼Œä¸¦å»é™¤é‡è¤‡æ’ç¨‹ (é€éçˆè™Ÿ)
    """
    now = pd.Timestamp.now()
    today = now.normalize()
    today_str = today.strftime("%Y-%m-%d")  # ç¢ºä¿ 'YYYY-MM-DD' æ ¼å¼

    # **å„è£½ç¨‹ç¨ç«‹åˆ¤æ–·é‡è¤‡**
    seen_furnace_ids = {
        "past": {"EAFA": set(), "EAFB": set(), "LF1-1": set(), "LF1-2": set()},
        "future": {"EAFA": set(), "EAFB": set(), "LF1-1": set(), "LF1-2": set()},
        "current": {"EAFA": set(), "EAFB": set(), "LF1-1": set(), "LF1-2": set()}
    }

    past_records, future_records, current_records = [], [], []

    ### **ğŸ”¹ è§£æ 2138 é é¢ (æ’ç¨‹)**
    quote_page = 'http://w3mes.dscsc.dragonsteel.com.tw/2138.aspx'
    http = urllib3.PoolManager()
    r = http.request('GET', quote_page)
    soup = BeautifulSoup(r.data, 'html.parser')

    contains = soup.find_all('area')
    schedule_data = []

    # **ä¸åŒè£½ç¨‹çš„æ™‚é–“åŒ¹é…æ¨¡å¼**
    time_patterns = {
        "EAFA": r"EAFAæ™‚é–“:\s*(\d{2}:\d{2}:\d{2})\s*~\s*(\d{2}:\d{2}:\d{2})",
        "EAFB": r"EAFBæ™‚é–“:\s*(\d{2}:\d{2}:\d{2})\s*~\s*(\d{2}:\d{2}:\d{2})",
        "LF1-1": r"LF1-1æ™‚é–“:\s*(\d{2}:\d{2}:\d{2})\s*~\s*(\d{2}:\d{2}:\d{2})",
        "LF1-2": r"LF1-2æ™‚é–“:\s*(\d{2}:\d{2}:\d{2})\s*~\s*(\d{2}:\d{2}:\d{2})"
    }

    for contain in contains:
        title_text = contain.get('title')

        # **å–å¾—çˆè™Ÿ**
        furnace_match = re.search(r"çˆè™Ÿ[ï¼>:\s]*([A-Za-z0-9]+)", title_text)
        furnace_id = furnace_match.group(1) if furnace_match else "æœªçŸ¥"

        # **è§£æåº§æ¨™**
        coords = re.findall(r"\d+", contain.get('coords'))
        if len(coords) < 2:
            continue
        x_coord = int(coords[0])  # X è»¸ä»£è¡¨æ™‚é–“
        y_coord = int(coords[1])  # Y è»¸ä»£è¡¨æ’ç¨‹åˆ†é¡

        # **æ ¹æ“š Y åº§æ¨™ç¯„åœåˆ¤æ–·è£½ç¨‹é¡å‹**
        if 179 <= y_coord <= 197:
            process_type = "EAFA"
        elif 217 <= y_coord <= 235:
            process_type = "EAFB"
        elif 250 <= y_coord <= 268:
            process_type = "LF1-1"
        elif 286 <= y_coord <= 304:
            process_type = "LF1-2"
        else:
            continue  # è‹¥ä¸åœ¨ä»»ä½•ç¯„åœå…§å‰‡è·³é

        # **æª¢æŸ¥ title æ˜¯å¦åŒ…å«å°æ‡‰è£½ç¨‹åç¨±**
        if process_type not in title_text:
            continue  # **å¦‚æœ title ä¸åŒ…å«è©²è£½ç¨‹åç¨±ï¼Œå‰‡è·³éè§£æ**

        # **è§£æé–‹å§‹èˆ‡çµæŸæ™‚é–“**
        time_match = re.search(time_patterns[process_type], title_text)
        if not time_match:
            # print(f"âš ï¸ ç„¡æ³•è§£æ {process_type} æ™‚é–“: {title_text}")
            continue  # å¦‚æœåŒ¹é…å¤±æ•—ï¼Œè·³éè©²æ’ç¨‹

        start_time = time_match.group(1)
        end_time = time_match.group(2)

        # **è½‰æ›æ™‚é–“æ ¼å¼**
        start = pd.to_datetime(f"{today} {start_time}")
        end = pd.to_datetime(f"{today} {end_time}")

        # **å­˜å…¥æ•¸æ“šï¼Œç¨å¾Œé€²è¡Œ X è»¸æ’åº**
        schedule_data.append((x_coord, start, end, furnace_id, process_type))

    # å»ºç«‹ sort_group æ¬„ä½ï¼šå°‡ EAFAã€EAFB åˆä½µç‚º EAFï¼Œå…¶å®ƒç¶­æŒåŸæ¨£
    def get_sort_group(process_type):
        if process_type in ["EAFA", "EAFB"]:
            return "EAF"
        return process_type

    # BUG å¾…è§£ã€‚å¦‚æœXè»¸éƒ½åœ¨118ï¼Œå°±å¿…éœ€è¦ç”¨èµ·å§‹æ™‚é–“ä¾†æ±ºå®šå…ˆå¾Œé—œä¿‚ï¼Œä¸ç„¶å¯èƒ½æœƒé€ æˆç¬¬2ä»¥(å«)ä¹‹å¾Œçš„æ’ç¨‹éƒ½+1å¤©.
    # å»ºç«‹æ’åºç”¨è³‡æ–™
    schedule_data_with_group = [
        (x_coord, start, end, furnace_id, process_type, get_sort_group(process_type))
        for (x_coord, start, end, furnace_id, process_type) in schedule_data
    ]

    # æ ¹æ“š sort_group èˆ‡ x_coord æ’åºï¼Œå¦‚æœx_coordç›¸åŒæ™‚ï¼Œå‰‡ç”¨èµ·å§‹æ™‚é–“æ’åº
    schedule_data_with_group.sort(key=lambda x: (x[5], x[0], x[1]))

    # ç§»é™¤æ’åºæ¬„ä½å¾Œï¼Œå›å¾©ç‚ºåŸæœ¬æ ¼å¼
    schedule_data = [(x[0], x[1], x[2], x[3], x[4]) for x in schedule_data_with_group]

    # **æ ¹æ“š X è»¸é€²è¡Œæ’åº**
    #schedule_data.sort(key=lambda x: (x[4], x[0]))  # å…ˆæŒ‰ process_type å†æŒ‰ X åº§æ¨™ æ’åº

    # **å»é™¤é‡è¤‡æ’ç¨‹ (ç›¸åŒçš„çˆè™Ÿid)**
    filtered_schedule = []
    for i in range(len(schedule_data)):
        if i > 0:
            curr_x, curr_start, curr_end, curr_furnace, curr_process = schedule_data[i]
            # **è®€å–å·²ç›¸åŒè£½ç¨‹å·²å­˜åœ¨çš„çˆè™Ÿid**
            furnace_list = [e[3] for e in filtered_schedule if e[4]==curr_process]
            # **å¦‚æœç›®å‰è™•ç†çš„çˆè™Ÿid å·±å­˜åœ¨ï¼Œå‰‡ä¸åŠ å…¥ filtered_schedule
            if curr_furnace in furnace_list:
                #print(f"âš ï¸ é‡è¤‡æ’ç¨‹ç§»é™¤: {curr_process} {curr_start} ~ {curr_end} (X={curr_x})")
                continue  # **è·³éé€™ç­†æ’ç¨‹ï¼Œä¸åŠ å…¥ filtered_schedule**

        filtered_schedule.append(schedule_data[i])

    # åŠ å…¥æª¢æŸ¥æ’ç¨‹æ™‚é–“éŒ¯äº‚åŠè·¨å¤©çš„é‚è¼¯
    for i in range(len(filtered_schedule)):
        curr_x, curr_start, curr_end, curr_furnace, curr_process = filtered_schedule[i]

        # å¦‚æœæ’ç¨‹çš„çµæŸæ™‚é–“æ¯”é–‹å§‹æ™‚é–“æ—©ï¼Œè¡¨ç¤ºè·¨å¤©ï¼ŒçµæŸæ™‚é–“éœ€åŠ ä¸€å¤©
        if curr_end < curr_start:
            curr_end += pd.Timedelta(days=1)

        # å¦‚æœç›®å‰ç³»çµ±æ™‚é–“åœ¨00:00~08:00, ä¸”è·é›¢æ’ç¨‹é–‹å§‹ç”Ÿç”¢çš„æ™‚é–“ï¼Œå¦‚æœè¶…é10å°æ™‚ä»¥ä¸Šï¼Œå‰‡åˆ¤æ–·ç‚ºå‰ä¸€å¤©å·²ç”Ÿç”¢å®Œçš„æ’ç¨‹
        now = pd.Timestamp.now()
        if now < (pd.Timestamp.today().normalize() + pd.offsets.Hour(8)):
            if (abs(now - curr_start)) > pd.Timedelta(hours=10):
                curr_start -= pd.Timedelta(days=1)
                curr_end -= pd.Timedelta(days=1)
        elif i == 0:    # å¦‚æœå‰é¢éƒ½æ²’æœ‰æ’ç¨‹ï¼Œé‡åˆ°ç¬¬ä¸€ç­†è³‡æ–™çš„æ—¥æœŸè¶…éç¾åœ¨10å°æ™‚ï¼Œå‰‡åˆ¤æ–·ç‚ºè·¨æ—¥çš„æ’ç¨‹ã€‚
            if abs(now - curr_start) > pd.Timedelta(hours=10):
                curr_start += pd.Timedelta(days=1)
                curr_end += pd.Timedelta(days=1)

        # å¦‚æœåŒä¸€è£½ç¨‹æœ‰å‰ä¸€ç­†æ’ç¨‹ï¼Œä¸”ç•¶å‰é–‹å§‹æ™‚é–“æ¯”å‰ä¸€æ’ç¨‹é–‹å§‹æ™‚é–“é‚„æ—©ï¼Œå‰‡è·¨å¤©ï¼Œéœ€åŠ ä¸€å¤© (EAFA å’Œ EAFB è¦–ç‚ºåŒä¸€ç¨®è£½ç¨‹)
        def unify_process(p):
            return "EAF" if p in ("EAFA", "EAFB") else p

        if i > 0:
            prev_x, prev_start, prev_end, prev_furnace, prev_process = filtered_schedule[i - 1]
            if unify_process(curr_process) == unify_process(prev_process) and curr_start < prev_start:
                curr_start += pd.Timedelta(days=1)
                curr_end += pd.Timedelta(days=1)

        # æ›´æ–° schedule_data ä¸­çš„è³‡æ–™
        filtered_schedule[i] = (curr_x, curr_start, curr_end, curr_furnace, curr_process)

    ### **ğŸ”¹ è§£æ 2137 é é¢ (ç²å–è£½ç¨‹ç‹€æ…‹)**
    quote_page_2137 = 'http://w3mes.dscsc.dragonsteel.com.tw/2137.aspx'
    r_2137 = http.request('GET', quote_page_2137)
    soup_2137 = BeautifulSoup(r_2137.data, 'html.parser')

    # **è§£æè£½ç¨‹ç‹€æ…‹**
    def get_status(soup, element_id):
        status_element = soup.find("span", {"id": element_id})
        return status_element.text.strip() if status_element else "æœªçŸ¥"

    process_status_mapping = {
        "EAFA": get_status(soup_2137, "lbl_eafa_period"),
        "EAFB": get_status(soup_2137, "lbl_eafb_period"),
        "LF1-1": get_status(soup_2137, "lbl_lf11_period"),
        "LF1-2": get_status(soup_2137, "lbl_lf12_period"),
    }

    # **åˆ†é¡ past / current / future**
    for x_coord, start, end, furnace_id, process_type in filtered_schedule:
        if end < now:
            if furnace_id not in seen_furnace_ids["past"][process_type]:
                past_records.append([start, end, furnace_id, process_type])
                seen_furnace_ids["past"][process_type].add(furnace_id)
        elif start > now:
            if furnace_id not in seen_furnace_ids["future"][process_type]:
                future_records.append([start, end, furnace_id, process_type])
                seen_furnace_ids["future"][process_type].add(furnace_id)
        else:
            if furnace_id not in seen_furnace_ids["current"][process_type]:
                process_status = process_status_mapping.get(process_type, "æœªçŸ¥")
                current_records.append([start, end, furnace_id, process_type, process_status])  # **ç¢ºä¿ è£½ç¨‹ç‹€æ…‹ å­˜åœ¨**
                seen_furnace_ids["current"][process_type].add(furnace_id)

    ### **ğŸ”¹ è½‰æ›ç‚º DataFrame**
    past_df = pd.DataFrame(past_records, columns=["é–‹å§‹æ™‚é–“", "çµæŸæ™‚é–“", "çˆè™Ÿ", "è£½ç¨‹"])
    current_df = pd.DataFrame(current_records, columns=["é–‹å§‹æ™‚é–“", "çµæŸæ™‚é–“", "çˆè™Ÿ", "è£½ç¨‹", "è£½ç¨‹ç‹€æ…‹"])
    future_df = pd.DataFrame(future_records, columns=["é–‹å§‹æ™‚é–“", "çµæŸæ™‚é–“", "çˆè™Ÿ", "è£½ç¨‹"])

    return past_df, current_df, future_df

scrapy_schedule()
